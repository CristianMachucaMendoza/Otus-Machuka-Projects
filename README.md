# Домашнее задание №2  
## Настройка облачной инфраструктуры для проекта по определению мошеннических транзакций

---

## Цель работы

В данном домашнем задании Вы познакомитесь с облачным провайдером **Yandex Cloud**, поработаете с сервисами **Object Storage** и **Yandex Data Processing**, создадите свой Spark-кластер и скопируете в него данные, научитесь оценивать затраты при проектировании облачной инфраструктуры.

---

## Описание проекта

Наконец-то! Оформив трудоустройство и уладив все формальности с юристами компании, Вы можете приступить к работе. В первую очередь, вас интересуют данные о транзакциях, которые были собраны за последние несколько лет. Пообщавшись с системным администратором, вы узнаете, что необходимая информация расположена в озере данных компании в объектном хранилище, доступном в режиме только для чтения по адресу:

`s3://otus-mlops-source-data/`

Поскольку это хранилище только для чтения, необходимо перенести данные в другое, уже ваше, хранилище для дальнейшей работы. Обычно для этого используют либо S3-bucket, либо HDFS.

Также, так как заказчик не может предоставить собственную вычислительную инфраструктуру, придется использовать облачные ресурсы. Поскольку данные находятся в Yandex Cloud, логично развернуть там и обработку данных.


## Кластер Yandex Data Processing

Spark-кластер должен иметь следующие характеристики:

- Мастер-подкластер: класс хоста `s3-c2-m8`, размер хранилища 40 ГБ  
- Data-подкластер: класс хоста `s3-c4-m16`, 3 хоста, размер хранилища 128 ГБ

## Задания

Результат работы ожидается в виде репозитория или ветки на GitHub с Terraform-конфигурациями и необходимым кодом для запуска системы.

### Обязательные задания

- Создать новый bucket в Yandex Cloud Object Storage с помощью Terraform-скрипта. Примеры можно найти в материалах занятия или на странице [документации Yandex Cloud](https://yandex.cloud/ru/docs/storage/tf-ref). Выкладывать скрипт в GitHub-репозиторий.

- Скопировать содержимое предоставленного хранилища с помощью инструмента `s3cmd`. Для проверки сделать bucket общедоступным и указать точку доступа в README вашего репозитория.

- Создать Spark-кластер в Yandex Data Processing с двумя подкластерами согласно характеристикам. Для экономии ресурсов использовать Terraform-скрипт для создания и удаления кластера (примеры есть в материалах занятия и документации [Yandex Cloud Data Proc](https://yandex.cloud/ru/docs/data-proc/tf-ref)). Выложить скрипт в GitHub-репозиторий.

- Подключиться по SSH к мастер-узлу и выполнить команду копирования содержимого хранилища в файловую систему HDFS с помощью `hadoop distcp`. Для проверки вывести содержимое HDFS-директории в консоль и приложить снимок экрана в README.

- Оценить месячные затраты на поддержание кластера, используя тарифный калькулятор Yandex Cloud. Сравнить стоимость содержания HDFS vs объектного хранилища.

### Дополнительные задания

- Предложить и реализовать способы оптимизации затрат на содержание Spark-кластера.

- Обновить статус задач на Kanban-доске GitHub Projects в соответствии с достигнутыми результатами. Внести коррективы при необходимости - разделить или объединить задачи.

- Полностью удалить созданный кластер с помощью команды `terraform destroy`, чтобы прекратить расходы на простои.

---

## Важные замечания

### Тарификация кластера

Даже при выключенном состоянии кластера облачный провайдер списывает средства за резервирование ресурсов. Это может быстро исчерпать средства на счёте. Не забывайте полностью удалять кластер после использования, это удобно делать через Terraform.

### Мониторинг затрат

На странице платежного аккаунта в Yandex Cloud есть раздел с детализацией биллинга за произвольный период. Через него можно отследить сумму потраченных средств на каждый используемый облачный сервис.

---

## Критерии оценки

Для положительной оценки нужно выполнить задания 1-4 и 8 из приведённого списка.

---

Желаем успехов!
equirements requirements.txt
    ```
https://storage.yandexcloud.net/otus-machuca-bucket-b1gjlbg9jdvuumq3kui1/